"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.CameraSource = void 0;
const hap_1 = require("./hap");
const camera_utils_1 = require("@homebridge/camera-utils");
const util_1 = require("../api/util");
const operators_1 = require("rxjs/operators");
const rxjs_1 = require("rxjs");
const fs_1 = require("fs");
const util_2 = require("util");
const rtp_utils_1 = require("../api/rtp-utils");
const ffmpeg_1 = require("../api/ffmpeg");
const readFileAsync = (0, util_2.promisify)(fs_1.readFile), cameraOfflinePath = require.resolve('../../media/camera-offline.jpg'), snapshotsBlockedPath = require.resolve('../../media/snapshots-blocked.jpg');
function getDurationSeconds(start) {
    return (Date.now() - start) / 1000;
}
class CameraSource {
    constructor(ringCamera) {
        this.ringCamera = ringCamera;
        this.controller = new hap_1.hap.CameraController({
            cameraStreamCount: 10,
            delegate: this,
            streamingOptions: {
                supportedCryptoSuites: [0 /* AES_CM_128_HMAC_SHA1_80 */],
                video: {
                    resolutions: [
                        [1280, 720, 30],
                        [1024, 768, 30],
                        [640, 480, 30],
                        [640, 360, 30],
                        [480, 360, 30],
                        [480, 270, 30],
                        [320, 240, 30],
                        [320, 240, 15],
                        [320, 180, 30],
                    ],
                    codec: {
                        profiles: [0 /* BASELINE */],
                        levels: [0 /* LEVEL3_1 */],
                    },
                },
                audio: {
                    codecs: [
                        {
                            type: "AAC-eld" /* AAC_ELD */,
                            samplerate: 16 /* KHZ_16 */,
                        },
                    ],
                },
            },
        });
        this.sessions = {};
    }
    loadSnapshot() {
        return __awaiter(this, void 0, void 0, function* () {
            // cache a promise of the snapshot load
            // This prevents multiple concurrent requests for snapshot from pilling up and creating lots of logs
            if (this.previousLoadSnapshotPromise) {
                return this.previousLoadSnapshotPromise;
            }
            this.previousLoadSnapshotPromise = this.loadAndCacheSnapshot();
            try {
                yield this.previousLoadSnapshotPromise;
            }
            catch (_) {
                // ignore errors
            }
            finally {
                // clear so another request can be made
                this.previousLoadSnapshotPromise = undefined;
            }
        });
    }
    loadAndCacheSnapshot() {
        return __awaiter(this, void 0, void 0, function* () {
            const start = Date.now();
            (0, util_1.logDebug)(`Loading new snapshot into cache for ${this.ringCamera.name}`);
            try {
                const previousSnapshot = this.cachedSnapshot, newSnapshot = yield this.ringCamera.getSnapshot();
                this.cachedSnapshot = newSnapshot;
                if (previousSnapshot !== newSnapshot) {
                    // Keep the snapshots in cache 2 minutes longer than their lifetime
                    // This allows users on LTE with wired camera to get snapshots each 60 second pull even though the cached snapshot is out of date
                    setTimeout(() => {
                        if (this.cachedSnapshot === newSnapshot) {
                            this.cachedSnapshot = undefined;
                        }
                    }, this.ringCamera.snapshotLifeTime + 2 * 60 * 1000);
                }
                (0, util_1.logDebug)(`Snapshot cached for ${this.ringCamera.name} (${getDurationSeconds(start)}s)`);
            }
            catch (e) {
                (0, util_1.logDebug)(`Failed to cache snapshot for ${this.ringCamera.name} (${getDurationSeconds(start)}s), The camera currently reports that it is ${this.ringCamera.isOffline ? 'offline' : 'online'}`);
            }
        });
    }
    getCurrentSnapshot() {
        if (this.ringCamera.isOffline) {
            return readFileAsync(cameraOfflinePath);
        }
        if (this.ringCamera.snapshotsAreBlocked) {
            return readFileAsync(snapshotsBlockedPath);
        }
        (0, util_1.logDebug)(`${this.cachedSnapshot ? 'Used cached snapshot' : 'No snapshot cached'} for ${this.ringCamera.name}`);
        if (!this.ringCamera.hasSnapshotWithinLifetime) {
            this.loadSnapshot().catch(util_1.logError);
        }
        // may or may not have a snapshot cached
        return this.cachedSnapshot;
    }
    handleSnapshotRequest(request, callback) {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                const snapshot = yield this.getCurrentSnapshot();
                if (!snapshot) {
                    // return an error to prevent "empty image buffer" warnings
                    return callback(new Error('No Snapshot Cached'));
                }
                // Not currently resizing the image.
                // HomeKit does a good job of resizing and doesn't seem to care if it's not right
                callback(undefined, snapshot);
            }
            catch (e) {
                (0, util_1.logError)(`Error fetching snapshot for ${this.ringCamera.name}`);
                (0, util_1.logError)(e);
                callback(e);
            }
        });
    }
    prepareStream(request, callback) {
        return __awaiter(this, void 0, void 0, function* () {
            const start = Date.now();
            (0, util_1.logInfo)(`Preparing Live Stream for ${this.ringCamera.name}`);
            try {
                const { sessionID, targetAddress, audio: { port: audioPort, srtp_key: audioSrtpKey, srtp_salt: audioSrtpSalt, }, video: { port: videoPort, srtp_key: videoSrtpKey, srtp_salt: videoSrtpSalt, }, } = request, ffmpegPath = (0, ffmpeg_1.getFfmpegPath)(), [sipSession, libfdkAacInstalled] = yield Promise.all([
                    this.ringCamera.createSipSession({
                        audio: {
                            srtpKey: audioSrtpKey,
                            srtpSalt: audioSrtpSalt,
                        },
                        video: {
                            srtpKey: videoSrtpKey,
                            srtpSalt: videoSrtpSalt,
                        },
                        skipFfmpegCheck: true,
                    }),
                    (0, camera_utils_1.doesFfmpegSupportCodec)('libfdk_aac', ffmpegPath)
                        .then((supported) => {
                        if (!supported) {
                            (0, util_1.logError)('Streaming video only - found ffmpeg, but libfdk_aac is not installed. See https://github.com/dgreif/ring/wiki/FFmpeg for details.');
                        }
                        return supported;
                    })
                        .catch(() => {
                        (0, util_1.logError)('Streaming video only - ffmpeg was not found. See https://github.com/dgreif/ring/wiki/FFmpeg for details.');
                        return false;
                    }),
                ]), onReturnPacketReceived = new rxjs_1.Subject();
                sipSession.addSubscriptions((0, rxjs_1.merge)((0, rxjs_1.of)(true).pipe((0, operators_1.delay)(15000)), onReturnPacketReceived)
                    .pipe((0, operators_1.debounceTime)(5000))
                    .subscribe(() => {
                    (0, util_1.logInfo)(`Live stream for ${this.ringCamera.name} appears to be inactive. (${getDurationSeconds(start)}s)`);
                    sipSession.stop();
                }));
                this.sessions[sessionID] = sipSession;
                const audioSsrc = hap_1.hap.CameraController.generateSynchronisationSource(), incomingAudioRtcpPort = yield sipSession.reservePort(), videoSsrcPromise = (0, rxjs_1.firstValueFrom)(sipSession.videoSplitter.onMessage.pipe((0, operators_1.filter)(({ info }) => info.address !== targetAddress), // Ignore return packets from HomeKit
                (0, operators_1.map)((m) => (0, camera_utils_1.getSsrc)(m.message)), (0, operators_1.filter)((ssrc) => ssrc !== null))).catch(() => 0), ringRtpDescription = yield sipSession.start(libfdkAacInstalled
                    ? {
                        input: ['-vn'],
                        audio: [
                            '-map',
                            '0:a',
                            // OPUS specific - it works, but audio is very choppy
                            // '-acodec',
                            // 'libopus',
                            // '-vbr',
                            // 'on',
                            // '-frame_duration',
                            // 20,
                            // '-application',
                            // 'lowdelay',
                            // AAC-eld specific
                            '-acodec',
                            'libfdk_aac',
                            '-profile:a',
                            'aac_eld',
                            // Shared options
                            '-flags',
                            '+global_header',
                            '-ac',
                            1,
                            '-ar',
                            '16k',
                            '-b:a',
                            '24k',
                            '-bufsize',
                            '24k',
                            '-payload_type',
                            110,
                            '-ssrc',
                            audioSsrc,
                            '-f',
                            'rtp',
                            '-srtp_out_suite',
                            'AES_CM_128_HMAC_SHA1_80',
                            '-srtp_out_params',
                            (0, camera_utils_1.encodeSrtpOptions)(sipSession.rtpOptions.audio),
                            `srtp://${targetAddress}:${audioPort}?localrtcpport=${incomingAudioRtcpPort}&pkt_size=188`,
                        ],
                        video: false,
                        output: [],
                    }
                    : undefined);
                let videoPacketReceived = false;
                sipSession.videoSplitter.addMessageHandler(({ info, message, isRtpMessage }) => {
                    if (info.address === targetAddress) {
                        // return packet from HomeKit
                        onReturnPacketReceived.next(null);
                        if (!isRtpMessage) {
                            // Only need to handle RTCP packets.  We really shouldn't receive RTP, but check just in case
                            sipSession.videoRtcpSplitter
                                .send(message, {
                                port: ringRtpDescription.video.rtcpPort,
                                address: ringRtpDescription.address,
                            })
                                .catch(util_1.logError);
                        }
                        // don't need to forward it along from the RTP splitter since it's only RTCP we care about
                        return null;
                    }
                    if ((0, rtp_utils_1.isStunMessage)(message) || !isRtpMessage) {
                        // we don't need to forward stun messages to HomeKit since they are for connection establishment purposes only
                        // if not rtp, probably rtcp which will be handled from rtcp splitter
                        return null;
                    }
                    if (!videoPacketReceived) {
                        videoPacketReceived = true;
                        (0, util_1.logInfo)(`Received stream data from ${this.ringCamera.name} (${getDurationSeconds(start)}s)`);
                    }
                    return {
                        port: videoPort,
                        address: targetAddress,
                    };
                });
                sipSession.videoRtcpSplitter.addMessageHandler(({ message, info, isRtpMessage }) => {
                    // for ICE connections, Rtcp splitter is the same as Rtp splitter, so we need to filter other messages out
                    if ((0, rtp_utils_1.isStunMessage)(message) ||
                        isRtpMessage ||
                        info.address === targetAddress) {
                        return null;
                    }
                    sipSession.videoSplitter
                        .send(message, {
                        port: videoPort,
                        address: targetAddress,
                    })
                        .catch(util_1.logError);
                    return null;
                });
                let returnAudioPort = null;
                if (libfdkAacInstalled) {
                    let cameraSpeakerActived = false;
                    const ringAudioLocation = {
                        address: ringRtpDescription.address,
                        port: ringRtpDescription.audio.port,
                    }, returnAudioTranscodedSplitter = new camera_utils_1.RtpSplitter((description) => {
                        if (!cameraSpeakerActived) {
                            cameraSpeakerActived = true;
                            sipSession.activateCameraSpeaker().catch(util_1.logError);
                        }
                        sipSession.audioSplitter
                            .send(description.message, ringAudioLocation)
                            .catch(util_1.logError);
                        return null;
                    }), returnAudioTranscoder = new camera_utils_1.ReturnAudioTranscoder({
                        prepareStreamRequest: request,
                        incomingAudioOptions: {
                            ssrc: audioSsrc,
                            rtcpPort: incomingAudioRtcpPort,
                        },
                        outputArgs: [
                            '-acodec',
                            'pcm_mulaw',
                            '-flags',
                            '+global_header',
                            '-ac',
                            1,
                            '-ar',
                            '8k',
                            '-f',
                            'rtp',
                            '-srtp_out_suite',
                            'AES_CM_128_HMAC_SHA1_80',
                            '-srtp_out_params',
                            (0, camera_utils_1.encodeSrtpOptions)(sipSession.rtpOptions.audio),
                            `srtp://127.0.0.1:${yield returnAudioTranscodedSplitter.portPromise}?pkt_size=188`,
                        ],
                        ffmpegPath,
                        logger: {
                            info: util_1.logDebug,
                            error: util_1.logError,
                        },
                        logLabel: `Return Audio (${this.ringCamera.name})`,
                    });
                    sipSession.onCallEnded.pipe((0, operators_1.take)(1)).subscribe(() => {
                        returnAudioTranscoder.stop();
                        returnAudioTranscodedSplitter.close();
                    });
                    returnAudioPort = yield returnAudioTranscoder.start();
                }
                let videoSsrc = ringRtpDescription.video.ssrc;
                if (videoSsrc) {
                    // Server supported ICE, which means response SDP included SSRC
                    (0, util_1.logInfo)(`Stream Prepared for ${this.ringCamera.name} (${getDurationSeconds(start)}s)`);
                }
                else {
                    // Server uses RTP latching.  Need to wait for first packet to determine SSRC
                    // NOTE: we could avoid this if we want to decrypt/re-encrypt each packets with a new SSRC
                    (0, util_1.logInfo)(`Waiting for stream data from ${this.ringCamera.name} (${getDurationSeconds(start)}s)`);
                    videoSsrc = yield videoSsrcPromise;
                }
                if (!videoSsrc) {
                    // failed to get video packet
                    (0, util_1.logInfo)(`Stream was closed before it was ready for ${this.ringCamera.name} (${getDurationSeconds(start)}s)`);
                    return callback(undefined);
                }
                callback(undefined, {
                    // SOMEDAY: remove address as it is not needed after homebridge 1.1.3
                    address: yield (0, camera_utils_1.getDefaultIpAddress)(request.addressVersion === 'ipv6'),
                    audio: {
                        // if audio isn't supported, pipe rtcp to incomingAudioRtcpPort which will not actually be bound
                        port: returnAudioPort || incomingAudioRtcpPort,
                        ssrc: audioSsrc,
                        srtp_key: audioSrtpKey,
                        srtp_salt: audioSrtpSalt,
                    },
                    video: {
                        port: yield sipSession.videoSplitter.portPromise,
                        ssrc: videoSsrc,
                        srtp_key: ringRtpDescription.video.srtpKey,
                        srtp_salt: ringRtpDescription.video.srtpSalt,
                    },
                });
            }
            catch (e) {
                (0, util_1.logError)(`Failed to prepare stream for ${this.ringCamera.name} (${getDurationSeconds(start)}s)`);
                (0, util_1.logError)(e);
                callback(e);
            }
        });
    }
    handleStreamRequest(request, callback) {
        const sessionID = request.sessionID, session = this.sessions[sessionID], requestType = request.type;
        if (!session) {
            callback(new Error('Cannot find session for stream ' + sessionID));
            return;
        }
        if (requestType === 'start') {
            (0, util_1.logInfo)(`Streaming active for ${this.ringCamera.name}`);
            // sip/rtp already started at this point, but request a key frame so that HomeKit for sure has one
            session.requestKeyFrame().catch(rxjs_1.noop);
        }
        else if (requestType === 'stop') {
            (0, util_1.logInfo)(`Stopped Live Stream for ${this.ringCamera.name}`);
            session.stop();
            delete this.sessions[sessionID];
        }
        callback();
    }
}
exports.CameraSource = CameraSource;
